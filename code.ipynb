{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './data/NEWS_YAHOO_stock_prediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove unnecessary column\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Step 2: Remove duplicate texts\n",
    "data.drop_duplicates(subset=['title', 'content'], inplace=True)\n",
    "\n",
    "# Step 3: Remove rows with large amount of spaces or empty texts in 'title' and 'content'\n",
    "data = data[~data['title'].str.isspace()]\n",
    "data = data[~data['content'].str.isspace()]\n",
    "data.dropna(subset=['title', 'content'], inplace=True)\n",
    "\n",
    "# Check the dataframe after these preprocessing steps\n",
    "data.info()\n",
    "\n",
    "# Step 5: Check for invalid numeric data\n",
    "numeric_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "data[numeric_columns].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) set proxy\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source ~/clash_dir/set && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "output\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the FinBERT model and tokenizer\n",
    "checkpoint = 'yiyanghkust/finbert-tone'\n",
    "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "\n",
    "# Create a pipeline for sentiment analysis\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, max_length=512, truncation=True, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply sentiment analysis to a dataframe\n",
    "def apply_sentiment_analysis(df, nlp, text_column='content'):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis to a column in a dataframe.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Dataframe containing the text data.\n",
    "    nlp (pipeline): HuggingFace pipeline for sentiment analysis.\n",
    "    text_column (str): Name of the column containing text data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with a new column 'sentiment' containing the analysis results.\n",
    "    \"\"\"\n",
    "    # Apply sentiment analysis to each row in the text column\n",
    "    sentiments = []\n",
    "    for text in df[text_column]:\n",
    "        try:\n",
    "            result = nlp(text)\n",
    "            sentiments.append(result[0]['label'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing text: {e}\")\n",
    "            sentiments.append('Error')\n",
    "\n",
    "    # Add the sentiments as a new column in the dataframe\n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def apply_sentiment_analysis_parallel(df, nlp, text_column='content', batch_size=10):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis in parallel to a column in a dataframe.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Dataframe containing the text data.\n",
    "    nlp (pipeline): HuggingFace pipeline for sentiment analysis.\n",
    "    text_column (str): Name of the column containing text data.\n",
    "    batch_size (int): Number of texts to process in parallel.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with a new column 'sentiment' containing the analysis results.\n",
    "    \"\"\"\n",
    "    # Define a function to process a batch of texts\n",
    "    def process_batch(texts):\n",
    "        return [nlp(text)[0]['label'] for text in texts]\n",
    "\n",
    "    # Break the texts into batches\n",
    "    batches = [df[text_column][i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "    # Process batches in parallel\n",
    "    sentiments = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for batch_result in tqdm(executor.map(process_batch, batches), total=len(batches)):\n",
    "            sentiments.extend(batch_result)\n",
    "\n",
    "    # Add the sentiments as a new column in the dataframe\n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the function\n",
    "# Note: You will run this on your local machine as it requires GPU support\n",
    "sample_texts = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
    "sample_df = pd.DataFrame(sample_texts, columns=['content'])\n",
    "apply_sentiment_analysis(sample_df, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the apply_sentiment_analysis function is defined as shown previously\n",
    "\n",
    "# Step 1: Apply sentiment analysis to the dataset\n",
    "# This step should be done on your local machine due to the requirement of GPU support\n",
    "data = apply_sentiment_analysis_parallel(data, nlp)\n",
    "\n",
    "# Step 2: Prepare data for the prediction model\n",
    "# Here we'll assume the sentiment analysis has been applied and 'sentiment' column is added to the data\n",
    "\n",
    "# We might want to convert sentiments to numerical values for model training\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "data['sentiment_numeric'] = data['sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to save the processed DataFrame to a CSV file\n",
    "data.to_csv('./data/dataset_with_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust display settings for better visualization of samples\n",
    "pd.set_option('display.max_colwidth', 200)  # Adjust the width to fit longer texts\n",
    "\n",
    "# Display some random samples with formatted output\n",
    "sample_data = data.sample(n=10)[['content', 'sentiment']]\n",
    "\n",
    "# Print each sample in a more readable format\n",
    "for index, row in sample_data.iterrows():\n",
    "    print(f\"Sample {index}:\")\n",
    "    print(f\"Content: {row['content']}\")\n",
    "    print(f\"Sentiment: {row['sentiment']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame with 'sentiment' and 'label' columns\n",
    "# Calculate the proportion of each sentiment category\n",
    "sentiment_counts = data['sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Calculate the proportion of each label\n",
    "label_counts = data['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Sentiment Distribution (%):\")\n",
    "print(sentiment_counts)\n",
    "print(\"\\nLabel Distribution (%):\")\n",
    "print(label_counts)\n",
    "\n",
    "# For additional insights, we can also look at the cross-tabulation of sentiment and label\n",
    "crosstab = pd.crosstab(data['sentiment'], data['label'], normalize='index') * 100\n",
    "print(\"\\nCross-Tabulation of Sentiment and Label (%):\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read for existed csv\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./data/dataset_with_sentiment.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime format and sort the dataframe by 'Date'\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data_sorted = data.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按 'Date' 和 'sentiment' 分组，然后计算每个类别的 category 为news和opinion的数量\n",
    "category_news_per_day_sentiment = data_sorted[data_sorted['category'] == 'news'].groupby(['Date', 'sentiment']).size().unstack().fillna(0)\n",
    "category_opinion_per_day_sentiment = data_sorted[data_sorted['category'] == 'opinion'].groupby(['Date', 'sentiment']).size().unstack().fillna(0)\n",
    "# 分别计算news和opinion的total\n",
    "category_news_total_per_day_sentiment = data_sorted[data_sorted['category'] == 'news'].groupby(['Date']).size()\n",
    "category_opinion_total_per_day_sentiment = data_sorted[data_sorted['category'] == 'opinion'].groupby(['Date']).size()\n",
    "\n",
    "data_sorted = data_sorted.set_index('Date')\n",
    "data_sorted['P_news_pos'] = category_news_per_day_sentiment['Positive'].reindex(data_sorted.index) / category_news_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted['P_news_neg'] = category_news_per_day_sentiment['Negative'].reindex(data_sorted.index) / category_news_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted['P_op_pos'] = category_opinion_per_day_sentiment['Positive'].reindex(data_sorted.index) / category_opinion_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted['P_op_neg'] = category_opinion_per_day_sentiment['Negative'].reindex(data_sorted.index) / category_opinion_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted = data_sorted.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = data_sorted.groupby('Date').last()\n",
    "\n",
    "# Shift the 'Open' column to get the next day's opening price\n",
    "daily_data['Next_Open'] = daily_data['Open'].shift(-1)\n",
    "\n",
    "# Drop the last row as it will not have a 'Next_Open' value\n",
    "daily_data = daily_data[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker                                                            AAPL\n",
       "category                                                       opinion\n",
       "title                   Dollar Sidelined  Krona Stabilizes  Rates Firm\n",
       "content              The main development here in the last full wee...\n",
       "Open                                                         28.467501\n",
       "High                                                           28.8025\n",
       "Low                                                          28.362499\n",
       "Close                                                            28.43\n",
       "Adj Close                                                    26.514231\n",
       "Volume                                                       151446800\n",
       "label                                                                0\n",
       "sentiment                                                      Neutral\n",
       "sentiment_numeric                                                    0\n",
       "P_news_pos                                                         0.0\n",
       "P_news_neg                                                         0.0\n",
       "P_op_pos                                                           0.5\n",
       "P_op_neg                                                         0.125\n",
       "Next_Open                                                      28.4125\n",
       "Name: 2016-10-28 00:00:00, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2016-10-28')\n",
    "daily_data.loc[(date_to_query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>P_news_pos</th>\n",
       "      <th>P_news_neg</th>\n",
       "      <th>P_op_pos</th>\n",
       "      <th>P_op_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Tech Earnings Roundup  Amazon  Alphabet  Apple...</td>\n",
       "      <td>On this special  short earnings edition of the...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Videogame Stock Roundup  Earnings In Focus  Ac...</td>\n",
       "      <td>Earnings reports were in the limelight this we...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Netflix And Amazon Video Absent From Apple s N...</td>\n",
       "      <td>During Apple Inc  s   NASDAQ AAPL   recent Mac...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Top Ranked ETFs To Buy On Alphabet s Robust Q3...</td>\n",
       "      <td>Google s parent company Alphabet Inc  s   NASD...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>The Zacks Stocks In The News Blog Highlights  ...</td>\n",
       "      <td>For Immediate Release\\nChicago  IL October 28 ...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Amazon targets Chinese demand for overseas sho...</td>\n",
       "      <td>BEIJING  Reuters    Amazon com Inc  NASDAQ AMZ...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>An End To The Earnings Recession</td>\n",
       "      <td>The growth picture emerging from the Q3 earnin...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Is Apple s Stock Cheap  Not To My Eyes</td>\n",
       "      <td>Apple  NASDAQ AAPL  reported earnings this wee...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Dollar Sidelined  Krona Stabilizes  Rates Firm</td>\n",
       "      <td>The main development here in the last full wee...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date ticker category  \\\n",
       "3891 2016-10-28   AAPL  opinion   \n",
       "3892 2016-10-28   AAPL  opinion   \n",
       "3893 2016-10-28   AAPL  opinion   \n",
       "3894 2016-10-28   AAPL  opinion   \n",
       "3895 2016-10-28   AAPL  opinion   \n",
       "3896 2016-10-28   AAPL     news   \n",
       "3897 2016-10-28   AAPL  opinion   \n",
       "3898 2016-10-28   AAPL  opinion   \n",
       "3899 2016-10-28   AAPL  opinion   \n",
       "\n",
       "                                                  title  \\\n",
       "3891  Tech Earnings Roundup  Amazon  Alphabet  Apple...   \n",
       "3892  Videogame Stock Roundup  Earnings In Focus  Ac...   \n",
       "3893  Netflix And Amazon Video Absent From Apple s N...   \n",
       "3894  Top Ranked ETFs To Buy On Alphabet s Robust Q3...   \n",
       "3895  The Zacks Stocks In The News Blog Highlights  ...   \n",
       "3896  Amazon targets Chinese demand for overseas sho...   \n",
       "3897                  An End To The Earnings Recession    \n",
       "3898             Is Apple s Stock Cheap  Not To My Eyes   \n",
       "3899     Dollar Sidelined  Krona Stabilizes  Rates Firm   \n",
       "\n",
       "                                                content       Open     High  \\\n",
       "3891  On this special  short earnings edition of the...  28.467501  28.8025   \n",
       "3892  Earnings reports were in the limelight this we...  28.467501  28.8025   \n",
       "3893  During Apple Inc  s   NASDAQ AAPL   recent Mac...  28.467501  28.8025   \n",
       "3894  Google s parent company Alphabet Inc  s   NASD...  28.467501  28.8025   \n",
       "3895  For Immediate Release\\nChicago  IL October 28 ...  28.467501  28.8025   \n",
       "3896  BEIJING  Reuters    Amazon com Inc  NASDAQ AMZ...  28.467501  28.8025   \n",
       "3897  The growth picture emerging from the Q3 earnin...  28.467501  28.8025   \n",
       "3898  Apple  NASDAQ AAPL  reported earnings this wee...  28.467501  28.8025   \n",
       "3899  The main development here in the last full wee...  28.467501  28.8025   \n",
       "\n",
       "            Low  Close  Adj Close     Volume  label sentiment  \\\n",
       "3891  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3892  28.362499  28.43  26.514231  151446800      0  Negative   \n",
       "3893  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "3894  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3895  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3896  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "3897  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3898  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "3899  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "\n",
       "      sentiment_numeric  P_news_pos  P_news_neg  P_op_pos  P_op_neg  \n",
       "3891                  1         0.0         0.0       0.5     0.125  \n",
       "3892                 -1         0.0         0.0       0.5     0.125  \n",
       "3893                  0         0.0         0.0       0.5     0.125  \n",
       "3894                  1         0.0         0.0       0.5     0.125  \n",
       "3895                  1         0.0         0.0       0.5     0.125  \n",
       "3896                  0         0.0         0.0       0.5     0.125  \n",
       "3897                  1         0.0         0.0       0.5     0.125  \n",
       "3898                  0         0.0         0.0       0.5     0.125  \n",
       "3899                  0         0.0         0.0       0.5     0.125  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2016-10-28')\n",
    "data_sorted.loc[data_sorted['Date'] == date_to_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker                                                            AAPL\n",
       "category                                                          news\n",
       "title                Apple Boosts Chip Orders From Main Foundry Sup...\n",
       "content              Apple s  NASDAQ AAPL  iPhone 11 has been selli...\n",
       "Open                                                         79.480003\n",
       "High                                                         79.889999\n",
       "Low                                                          78.912498\n",
       "Close                                                        79.807503\n",
       "Adj Close                                                    78.315315\n",
       "Volume                                                       104472000\n",
       "label                                                                1\n",
       "sentiment                                                     Positive\n",
       "sentiment_numeric                                                    1\n",
       "P_news_pos                                                    0.461538\n",
       "P_news_neg                                                    0.076923\n",
       "P_op_pos                                                      0.909091\n",
       "P_op_neg                                                           0.0\n",
       "Next_Open                                                      80.0625\n",
       "Name: 2020-01-23 00:00:00, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2020-01-23')\n",
    "daily_data.loc[(date_to_query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot perform 'rand_' with a dtyped [object] array and scalar of type [bool]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:364\u001b[0m, in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    356\u001b[0m     \u001b[39m# For exposition, write:\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39m#  yarr = isinstance(y, np.ndarray)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[39m# Then Cases where this goes through without raising include:\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39m#  (xint or xbool) and (yint or bool)\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     result \u001b[39m=\u001b[39m op(x, y)\n\u001b[1;32m    365\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/roperator.py:54\u001b[0m, in \u001b[0;36mrand_\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrand_\u001b[39m(left, right):\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m operator\u001b[39m.\u001b[39;49mand_(right, left)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'Timestamp' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:378\u001b[0m, in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_binop(x, y, op)\n\u001b[1;32m    379\u001b[0m \u001b[39mexcept\u001b[39;00m (\n\u001b[1;32m    380\u001b[0m     \u001b[39mTypeError\u001b[39;00m,\n\u001b[1;32m    381\u001b[0m     \u001b[39mValueError\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[39mNotImplementedError\u001b[39;00m,\n\u001b[1;32m    385\u001b[0m ) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mops.pyx:210\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_binop\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/roperator.py:54\u001b[0m, in \u001b[0;36mrand_\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrand_\u001b[39m(left, right):\n\u001b[0;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m operator\u001b[39m.\u001b[39;49mand_(right, left)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for &: 'bool' and 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/root/Workspace/Playground/code.ipynb 单元格 18\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bconnect.beijinga.seetacloud.com/root/Workspace/Playground/code.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m date_to_query \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(\u001b[39m'\u001b[39m\u001b[39m2018-05-06\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bconnect.beijinga.seetacloud.com/root/Workspace/Playground/code.ipynb#X51sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m data_sorted\u001b[39m.\u001b[39mloc[data_sorted[\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m date_to_query \u001b[39m&\u001b[39;49m data_sorted[\u001b[39m'\u001b[39;49m\u001b[39mcategory\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnews\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/arraylike.py:74\u001b[0m, in \u001b[0;36mOpsMixin.__rand__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__rand__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__rand__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m---> 74\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_logical_method(other, roperator\u001b[39m.\u001b[39;49mrand_)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/series.py:5810\u001b[0m, in \u001b[0;36mSeries._logical_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5807\u001b[0m lvalues \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[1;32m   5808\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 5810\u001b[0m res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mlogical_op(lvalues, rvalues, op)\n\u001b[1;32m   5811\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:456\u001b[0m, in \u001b[0;36mlogical_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     \u001b[39m# i.e. scalar\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     is_other_int_dtype \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mis_integer(rvalues)\n\u001b[0;32m--> 456\u001b[0m res_values \u001b[39m=\u001b[39m na_logical_op(lvalues, rvalues, op)\n\u001b[1;32m    458\u001b[0m \u001b[39m# For int vs int `^`, `|`, `&` are bitwise operators and return\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m#   integer dtypes.  Otherwise these are boolean ops\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (left\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39miu\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m is_other_int_dtype):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/ops/array_ops.py:387\u001b[0m, in \u001b[0;36mna_logical_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[39mexcept\u001b[39;00m (\n\u001b[1;32m    380\u001b[0m             \u001b[39mTypeError\u001b[39;00m,\n\u001b[1;32m    381\u001b[0m             \u001b[39mValueError\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[39mNotImplementedError\u001b[39;00m,\n\u001b[1;32m    385\u001b[0m         ) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    386\u001b[0m             typ \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(y)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[0;32m--> 387\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot perform \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mop\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m with a dtyped [\u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m] array \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mand scalar of type [\u001b[39m\u001b[39m{\u001b[39;00mtyp\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot perform 'rand_' with a dtyped [object] array and scalar of type [bool]"
     ]
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2018-05-06')\n",
    "data_sorted.loc[data_sorted['Date'] == date_to_query & data_sorted['category'] == 'news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>P_news_pos</th>\n",
       "      <th>P_news_neg</th>\n",
       "      <th>P_op_pos</th>\n",
       "      <th>P_op_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Apple and Buffett saw value  and acted</td>\n",
       "      <td>By Noel Randewich SAN FRANCISCO  Reuters    Ap...</td>\n",
       "      <td>48.267502</td>\n",
       "      <td>48.485001</td>\n",
       "      <td>48.09</td>\n",
       "      <td>48.327499</td>\n",
       "      <td>46.396736</td>\n",
       "      <td>86264000</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.12963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Buffett craves more Apple shares  endorses its...</td>\n",
       "      <td>By Trevor Hunnicutt and Jonathan Stempel OMAHA...</td>\n",
       "      <td>48.267502</td>\n",
       "      <td>48.485001</td>\n",
       "      <td>48.09</td>\n",
       "      <td>48.327499</td>\n",
       "      <td>46.396736</td>\n",
       "      <td>86264000</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.12963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date ticker category  \\\n",
       "9679 2018-05-06   AAPL     news   \n",
       "9680 2018-05-06   AAPL     news   \n",
       "\n",
       "                                                  title  \\\n",
       "9679             Apple and Buffett saw value  and acted   \n",
       "9680  Buffett craves more Apple shares  endorses its...   \n",
       "\n",
       "                                                content       Open       High  \\\n",
       "9679  By Noel Randewich SAN FRANCISCO  Reuters    Ap...  48.267502  48.485001   \n",
       "9680  By Trevor Hunnicutt and Jonathan Stempel OMAHA...  48.267502  48.485001   \n",
       "\n",
       "        Low      Close  Adj Close    Volume  label sentiment  \\\n",
       "9679  48.09  48.327499  46.396736  86264000      1   Neutral   \n",
       "9680  48.09  48.327499  46.396736  86264000      1   Neutral   \n",
       "\n",
       "      sentiment_numeric  P_news_pos  P_news_neg  P_op_pos  P_op_neg  \n",
       "9679                  0         0.0         0.0  0.814815   0.12963  \n",
       "9680                  0         0.0         0.0  0.814815   0.12963  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2018-05-06')\n",
    "category_to_query = 'news'\n",
    "data_sorted.loc[(data_sorted['Date'] == date_to_query) & (data_sorted['category'] == category_to_query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data['P_news_neg'].fillna(0, inplace=True)\n",
    "daily_data['P_news_pos'].fillna(0, inplace=True)\n",
    "daily_data['P_op_neg'].fillna(0, inplace=True)\n",
    "daily_data['P_op_pos'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不直接删除，而是存到新的df中\n",
    "columns_to_keep = [col for col in daily_data.columns if col not in ['ticker', 'Adj Close', 'sentiment', 'sentiment_numeric', 'title', 'category', 'content', 'label']]\n",
    "daily_data_selected = daily_data[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_selected.to_csv('./data/dataset_for_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据指示，选择特征和目标\n",
    "features = daily_data_selected.drop('Next_Open', axis=1)\n",
    "target = daily_data_selected['Next_Open']\n",
    "\n",
    "# normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Apply the MinMaxScaler to the features and target\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "scaled_features = scaler_features.fit_transform(features)\n",
    "scaled_target = scaler_target.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "# Create new DataFrames with the scaled features and target\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "scaled_target_df = pd.DataFrame(scaled_target, columns=['Next_Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          Open      High       Low     Close    Volume  P_news_pos  \\\n",
       " 1648  0.984971  0.982760  0.990400  0.998102  0.065259    0.500000   \n",
       " 1649  0.988445  0.983812  0.994210  0.989903  0.046202    0.200000   \n",
       " 1650  0.993694  0.987455  0.999200  0.994192  0.039836    0.333333   \n",
       " 1651  0.991202  0.985840  0.992876  1.000000  0.041701    0.461538   \n",
       " 1652  1.000000  1.000000  1.000000  0.996508  0.071421    0.416667   \n",
       " \n",
       "       P_news_neg  P_op_pos  P_op_neg  \n",
       " 1648    0.250000  0.700000  0.000000  \n",
       " 1649    0.200000  0.523810  0.238095  \n",
       " 1650    0.200000  0.666667  0.066667  \n",
       " 1651    0.076923  0.909091  0.000000  \n",
       " 1652    0.166667  0.750000  0.000000  ,\n",
       "       Next_Open\n",
       " 1648   0.988445\n",
       " 1649   0.993694\n",
       " 1650   0.991202\n",
       " 1651   1.000000\n",
       " 1652   0.961522)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features_df.tail(), scaled_target_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from transformers import TimeSeriesTransformerForPrediction\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 将数据转换为Tensor\n",
    "features_tensor = torch.tensor(scaled_features, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(scaled_target, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "past_observed_mask = torch.ones_like(features_tensor, dtype=torch.bool)\n",
    "\n",
    "# 划分训练集和测试集\n",
    "train_features, test_features, train_target, test_target = train_test_split(features_tensor, target_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# 创建TensorDataset\n",
    "train_dataset = TensorDataset(train_features, train_target)\n",
    "test_dataset = TensorDataset(test_features, test_target)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = TimeSeriesTransformerForPrediction.from_pretrained(\"huggingface/time-series-transformer-tourism-monthly\", num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# 设置超参数\n",
    "num_epochs = 10  # 定义训练的迭代次数\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        outputs = model(\n",
    "        past_values=batch[\"past_values\"],\n",
    "        past_time_features=batch[\"past_time_features\"],\n",
    "        past_observed_mask=batch[\"past_observed_mask\"],\n",
    "        static_categorical_features=batch[\"static_categorical_features\"],\n",
    "        static_real_features=batch[\"static_real_features\"],\n",
    "        future_values=batch[\"future_values\"],\n",
    "        future_time_features=batch[\"future_time_features\"],\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        # # 分离特征和标签\n",
    "        # inputs, labels = batch\n",
    "\n",
    "        # # 根据inputs准备past_observed_mask\n",
    "        # # 如果没有缺失值，可以使用全为True的张量\n",
    "        # past_observed_mask = torch.ones_like(inputs, dtype=torch.bool)\n",
    "\n",
    "        # # 重置梯度\n",
    "        # optimizer.zero_grad()\n",
    "        \n",
    "        # # 前向传播，确保使用正确的参数\n",
    "        # outputs = model(inputs, past_observed_mask)\n",
    "\n",
    "        # # 计算损失\n",
    "        # loss = criterion(outputs, labels)\n",
    "\n",
    "        # # 后向传播和优化\n",
    "        # loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 累计损失\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测和评估\n",
    "model.eval()\n",
    "predictions, actuals = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        outputs = model(inputs)\n",
    "        predictions.extend(outputs.numpy())\n",
    "        actuals.extend(labels.numpy())\n",
    "\n",
    "# 假设 predictions 和 actuals 是模型的预测结果和实际目标值\n",
    "predictions_tensor = torch.tensor(predictions, dtype=torch.float32)\n",
    "actuals_tensor = torch.tensor(actuals, dtype=torch.float32)\n",
    "\n",
    "# 将预测结果和实际值转换回原始尺度\n",
    "predicted_prices = scaler_target.inverse_transform(predictions_tensor.numpy())\n",
    "actual_prices = scaler_target.inverse_transform(actuals_tensor.numpy())\n",
    "\n",
    "# 可视化预测结果\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(actuals, label='Actual')\n",
    "plt.plot(predictions, label='Predicted')\n",
    "plt.title('Time Series Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Normalized Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
