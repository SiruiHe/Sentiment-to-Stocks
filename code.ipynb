{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = './data/NEWS_YAHOO_stock_prediction.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove unnecessary column\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Step 2: Remove duplicate texts\n",
    "data.drop_duplicates(subset=['title', 'content'], inplace=True)\n",
    "\n",
    "# Step 3: Remove rows with large amount of spaces or empty texts in 'title' and 'content'\n",
    "data = data[~data['title'].str.isspace()]\n",
    "data = data[~data['content'].str.isspace()]\n",
    "data.dropna(subset=['title', 'content'], inplace=True)\n",
    "\n",
    "# Check the dataframe after these preprocessing steps\n",
    "data.info()\n",
    "\n",
    "# Step 5: Check for invalid numeric data\n",
    "numeric_columns = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']\n",
    "data[numeric_columns].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) set proxy\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "result = subprocess.run('bash -c \"source ~/clash_dir/set && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
    "output = result.stdout\n",
    "output\n",
    "for line in output.splitlines():\n",
    "    if '=' in line:\n",
    "        var, value = line.split('=', 1)\n",
    "        os.environ[var] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load the FinBERT model and tokenizer\n",
    "checkpoint = 'yiyanghkust/finbert-tone'\n",
    "tokenizer = BertTokenizer.from_pretrained(checkpoint)\n",
    "model = BertForSequenceClassification.from_pretrained(checkpoint, num_labels=3)\n",
    "\n",
    "# Create a pipeline for sentiment analysis\n",
    "nlp = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer, max_length=512, truncation=True, device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply sentiment analysis to a dataframe\n",
    "def apply_sentiment_analysis(df, nlp, text_column='content'):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis to a column in a dataframe.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Dataframe containing the text data.\n",
    "    nlp (pipeline): HuggingFace pipeline for sentiment analysis.\n",
    "    text_column (str): Name of the column containing text data.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with a new column 'sentiment' containing the analysis results.\n",
    "    \"\"\"\n",
    "    # Apply sentiment analysis to each row in the text column\n",
    "    sentiments = []\n",
    "    for text in df[text_column]:\n",
    "        try:\n",
    "            result = nlp(text)\n",
    "            sentiments.append(result[0]['label'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error in processing text: {e}\")\n",
    "            sentiments.append('Error')\n",
    "\n",
    "    # Add the sentiments as a new column in the dataframe\n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def apply_sentiment_analysis_parallel(df, nlp, text_column='content', batch_size=10):\n",
    "    \"\"\"\n",
    "    Apply sentiment analysis in parallel to a column in a dataframe.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): Dataframe containing the text data.\n",
    "    nlp (pipeline): HuggingFace pipeline for sentiment analysis.\n",
    "    text_column (str): Name of the column containing text data.\n",
    "    batch_size (int): Number of texts to process in parallel.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Dataframe with a new column 'sentiment' containing the analysis results.\n",
    "    \"\"\"\n",
    "    # Define a function to process a batch of texts\n",
    "    def process_batch(texts):\n",
    "        return [nlp(text)[0]['label'] for text in texts]\n",
    "\n",
    "    # Break the texts into batches\n",
    "    batches = [df[text_column][i:i + batch_size] for i in range(0, len(df), batch_size)]\n",
    "\n",
    "    # Process batches in parallel\n",
    "    sentiments = []\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        for batch_result in tqdm(executor.map(process_batch, batches), total=len(batches)):\n",
    "            sentiments.extend(batch_result)\n",
    "\n",
    "    # Add the sentiments as a new column in the dataframe\n",
    "    df['sentiment'] = sentiments\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the function\n",
    "# Note: You will run this on your local machine as it requires GPU support\n",
    "sample_texts = [\"I've been waiting for a HuggingFace course my whole life.\", \"So have I!\"]\n",
    "sample_df = pd.DataFrame(sample_texts, columns=['content'])\n",
    "apply_sentiment_analysis(sample_df, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the apply_sentiment_analysis function is defined as shown previously\n",
    "\n",
    "# Step 1: Apply sentiment analysis to the dataset\n",
    "# This step should be done on your local machine due to the requirement of GPU support\n",
    "data = apply_sentiment_analysis_parallel(data, nlp)\n",
    "\n",
    "# Step 2: Prepare data for the prediction model\n",
    "# Here we'll assume the sentiment analysis has been applied and 'sentiment' column is added to the data\n",
    "\n",
    "# We might want to convert sentiments to numerical values for model training\n",
    "sentiment_mapping = {'Positive': 1, 'Neutral': 0, 'Negative': -1}\n",
    "data['sentiment_numeric'] = data['sentiment'].map(sentiment_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to save the processed DataFrame to a CSV file\n",
    "data.to_csv('./data/dataset_with_sentiment.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust display settings for better visualization of samples\n",
    "pd.set_option('display.max_colwidth', 200)  # Adjust the width to fit longer texts\n",
    "\n",
    "# Display some random samples with formatted output\n",
    "sample_data = data.sample(n=10)[['content', 'sentiment']]\n",
    "\n",
    "# Print each sample in a more readable format\n",
    "for index, row in sample_data.iterrows():\n",
    "    print(f\"Sample {index}:\")\n",
    "    print(f\"Content: {row['content']}\")\n",
    "    print(f\"Sentiment: {row['sentiment']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your DataFrame with 'sentiment' and 'label' columns\n",
    "# Calculate the proportion of each sentiment category\n",
    "sentiment_counts = data['sentiment'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Calculate the proportion of each label\n",
    "label_counts = data['label'].value_counts(normalize=True) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Sentiment Distribution (%):\")\n",
    "print(sentiment_counts)\n",
    "print(\"\\nLabel Distribution (%):\")\n",
    "print(label_counts)\n",
    "\n",
    "# For additional insights, we can also look at the cross-tabulation of sentiment and label\n",
    "crosstab = pd.crosstab(data['sentiment'], data['label'], normalize='index') * 100\n",
    "print(\"\\nCross-Tabulation of Sentiment and Label (%):\")\n",
    "print(crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read for existed csv\n",
    "import pandas as pd\n",
    "data = pd.read_csv('./data/dataset_with_sentiment.csv')\n",
    "\n",
    "# Convert the 'Date' column to datetime format and sort the dataframe by 'Date'\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data_sorted = data.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 按 'Date' 和 'sentiment' 分组，然后计算每个类别的 category 为news和opinion的数量\n",
    "category_news_per_day_sentiment = data_sorted[data_sorted['category'] == 'news'].groupby(['Date', 'sentiment']).size().unstack().fillna(0)\n",
    "category_opinion_per_day_sentiment = data_sorted[data_sorted['category'] == 'opinion'].groupby(['Date', 'sentiment']).size().unstack().fillna(0)\n",
    "# 分别计算news和opinion的total\n",
    "category_news_total_per_day_sentiment = data_sorted[data_sorted['category'] == 'news'].groupby(['Date']).size()\n",
    "category_opinion_total_per_day_sentiment = data_sorted[data_sorted['category'] == 'opinion'].groupby(['Date']).size()\n",
    "\n",
    "data_sorted = data_sorted.set_index('Date')\n",
    "data_sorted['P_news_pos'] = category_news_per_day_sentiment['Positive'].reindex(data_sorted.index) / category_news_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted['P_news_neg'] = category_news_per_day_sentiment['Negative'].reindex(data_sorted.index) / category_news_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted['P_op_pos'] = category_opinion_per_day_sentiment['Positive'].reindex(data_sorted.index) / category_opinion_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted['P_op_neg'] = category_opinion_per_day_sentiment['Negative'].reindex(data_sorted.index) / category_opinion_total_per_day_sentiment.reindex(data_sorted.index)\n",
    "data_sorted = data_sorted.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data = data_sorted.groupby('Date').last()\n",
    "\n",
    "# Shift the 'Open' column to get the next day's opening price\n",
    "daily_data['Next_Open'] = daily_data['Open'].shift(-1)\n",
    "\n",
    "# Drop the last row as it will not have a 'Next_Open' value\n",
    "daily_data = daily_data[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker                                                            AAPL\n",
       "category                                                       opinion\n",
       "title                   Dollar Sidelined  Krona Stabilizes  Rates Firm\n",
       "content              The main development here in the last full wee...\n",
       "Open                                                         28.467501\n",
       "High                                                           28.8025\n",
       "Low                                                          28.362499\n",
       "Close                                                            28.43\n",
       "Adj Close                                                    26.514231\n",
       "Volume                                                       151446800\n",
       "label                                                                0\n",
       "sentiment                                                      Neutral\n",
       "sentiment_numeric                                                    0\n",
       "P_news_pos                                                         0.0\n",
       "P_news_neg                                                         0.0\n",
       "P_op_pos                                                           0.5\n",
       "P_op_neg                                                         0.125\n",
       "Next_Open                                                      28.4125\n",
       "Name: 2016-10-28 00:00:00, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2016-10-28')\n",
    "daily_data.loc[(date_to_query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>P_news_pos</th>\n",
       "      <th>P_news_neg</th>\n",
       "      <th>P_op_pos</th>\n",
       "      <th>P_op_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Tech Earnings Roundup  Amazon  Alphabet  Apple...</td>\n",
       "      <td>On this special  short earnings edition of the...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Videogame Stock Roundup  Earnings In Focus  Ac...</td>\n",
       "      <td>Earnings reports were in the limelight this we...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3893</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Netflix And Amazon Video Absent From Apple s N...</td>\n",
       "      <td>During Apple Inc  s   NASDAQ AAPL   recent Mac...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3894</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Top Ranked ETFs To Buy On Alphabet s Robust Q3...</td>\n",
       "      <td>Google s parent company Alphabet Inc  s   NASD...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3895</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>The Zacks Stocks In The News Blog Highlights  ...</td>\n",
       "      <td>For Immediate Release\\nChicago  IL October 28 ...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3896</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Amazon targets Chinese demand for overseas sho...</td>\n",
       "      <td>BEIJING  Reuters    Amazon com Inc  NASDAQ AMZ...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3897</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>An End To The Earnings Recession</td>\n",
       "      <td>The growth picture emerging from the Q3 earnin...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3898</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Is Apple s Stock Cheap  Not To My Eyes</td>\n",
       "      <td>Apple  NASDAQ AAPL  reported earnings this wee...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>opinion</td>\n",
       "      <td>Dollar Sidelined  Krona Stabilizes  Rates Firm</td>\n",
       "      <td>The main development here in the last full wee...</td>\n",
       "      <td>28.467501</td>\n",
       "      <td>28.8025</td>\n",
       "      <td>28.362499</td>\n",
       "      <td>28.43</td>\n",
       "      <td>26.514231</td>\n",
       "      <td>151446800</td>\n",
       "      <td>0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date ticker category  \\\n",
       "3891 2016-10-28   AAPL  opinion   \n",
       "3892 2016-10-28   AAPL  opinion   \n",
       "3893 2016-10-28   AAPL  opinion   \n",
       "3894 2016-10-28   AAPL  opinion   \n",
       "3895 2016-10-28   AAPL  opinion   \n",
       "3896 2016-10-28   AAPL     news   \n",
       "3897 2016-10-28   AAPL  opinion   \n",
       "3898 2016-10-28   AAPL  opinion   \n",
       "3899 2016-10-28   AAPL  opinion   \n",
       "\n",
       "                                                  title  \\\n",
       "3891  Tech Earnings Roundup  Amazon  Alphabet  Apple...   \n",
       "3892  Videogame Stock Roundup  Earnings In Focus  Ac...   \n",
       "3893  Netflix And Amazon Video Absent From Apple s N...   \n",
       "3894  Top Ranked ETFs To Buy On Alphabet s Robust Q3...   \n",
       "3895  The Zacks Stocks In The News Blog Highlights  ...   \n",
       "3896  Amazon targets Chinese demand for overseas sho...   \n",
       "3897                  An End To The Earnings Recession    \n",
       "3898             Is Apple s Stock Cheap  Not To My Eyes   \n",
       "3899     Dollar Sidelined  Krona Stabilizes  Rates Firm   \n",
       "\n",
       "                                                content       Open     High  \\\n",
       "3891  On this special  short earnings edition of the...  28.467501  28.8025   \n",
       "3892  Earnings reports were in the limelight this we...  28.467501  28.8025   \n",
       "3893  During Apple Inc  s   NASDAQ AAPL   recent Mac...  28.467501  28.8025   \n",
       "3894  Google s parent company Alphabet Inc  s   NASD...  28.467501  28.8025   \n",
       "3895  For Immediate Release\\nChicago  IL October 28 ...  28.467501  28.8025   \n",
       "3896  BEIJING  Reuters    Amazon com Inc  NASDAQ AMZ...  28.467501  28.8025   \n",
       "3897  The growth picture emerging from the Q3 earnin...  28.467501  28.8025   \n",
       "3898  Apple  NASDAQ AAPL  reported earnings this wee...  28.467501  28.8025   \n",
       "3899  The main development here in the last full wee...  28.467501  28.8025   \n",
       "\n",
       "            Low  Close  Adj Close     Volume  label sentiment  \\\n",
       "3891  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3892  28.362499  28.43  26.514231  151446800      0  Negative   \n",
       "3893  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "3894  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3895  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3896  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "3897  28.362499  28.43  26.514231  151446800      0  Positive   \n",
       "3898  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "3899  28.362499  28.43  26.514231  151446800      0   Neutral   \n",
       "\n",
       "      sentiment_numeric  P_news_pos  P_news_neg  P_op_pos  P_op_neg  \n",
       "3891                  1         0.0         0.0       0.5     0.125  \n",
       "3892                 -1         0.0         0.0       0.5     0.125  \n",
       "3893                  0         0.0         0.0       0.5     0.125  \n",
       "3894                  1         0.0         0.0       0.5     0.125  \n",
       "3895                  1         0.0         0.0       0.5     0.125  \n",
       "3896                  0         0.0         0.0       0.5     0.125  \n",
       "3897                  1         0.0         0.0       0.5     0.125  \n",
       "3898                  0         0.0         0.0       0.5     0.125  \n",
       "3899                  0         0.0         0.0       0.5     0.125  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2016-10-28')\n",
    "data_sorted.loc[data_sorted['Date'] == date_to_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker                                                            AAPL\n",
       "category                                                          news\n",
       "title                Apple Boosts Chip Orders From Main Foundry Sup...\n",
       "content              Apple s  NASDAQ AAPL  iPhone 11 has been selli...\n",
       "Open                                                         79.480003\n",
       "High                                                         79.889999\n",
       "Low                                                          78.912498\n",
       "Close                                                        79.807503\n",
       "Adj Close                                                    78.315315\n",
       "Volume                                                       104472000\n",
       "label                                                                1\n",
       "sentiment                                                     Positive\n",
       "sentiment_numeric                                                    1\n",
       "P_news_pos                                                    0.461538\n",
       "P_news_neg                                                    0.076923\n",
       "P_op_pos                                                      0.909091\n",
       "P_op_neg                                                           0.0\n",
       "Next_Open                                                      80.0625\n",
       "Name: 2020-01-23 00:00:00, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2020-01-23')\n",
    "daily_data.loc[(date_to_query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>P_news_pos</th>\n",
       "      <th>P_news_neg</th>\n",
       "      <th>P_op_pos</th>\n",
       "      <th>P_op_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9679</th>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Apple and Buffett saw value  and acted</td>\n",
       "      <td>By Noel Randewich SAN FRANCISCO  Reuters    Ap...</td>\n",
       "      <td>48.267502</td>\n",
       "      <td>48.485001</td>\n",
       "      <td>48.09</td>\n",
       "      <td>48.327499</td>\n",
       "      <td>46.396736</td>\n",
       "      <td>86264000</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.12963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9680</th>\n",
       "      <td>2018-05-06</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>news</td>\n",
       "      <td>Buffett craves more Apple shares  endorses its...</td>\n",
       "      <td>By Trevor Hunnicutt and Jonathan Stempel OMAHA...</td>\n",
       "      <td>48.267502</td>\n",
       "      <td>48.485001</td>\n",
       "      <td>48.09</td>\n",
       "      <td>48.327499</td>\n",
       "      <td>46.396736</td>\n",
       "      <td>86264000</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.12963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date ticker category  \\\n",
       "9679 2018-05-06   AAPL     news   \n",
       "9680 2018-05-06   AAPL     news   \n",
       "\n",
       "                                                  title  \\\n",
       "9679             Apple and Buffett saw value  and acted   \n",
       "9680  Buffett craves more Apple shares  endorses its...   \n",
       "\n",
       "                                                content       Open       High  \\\n",
       "9679  By Noel Randewich SAN FRANCISCO  Reuters    Ap...  48.267502  48.485001   \n",
       "9680  By Trevor Hunnicutt and Jonathan Stempel OMAHA...  48.267502  48.485001   \n",
       "\n",
       "        Low      Close  Adj Close    Volume  label sentiment  \\\n",
       "9679  48.09  48.327499  46.396736  86264000      1   Neutral   \n",
       "9680  48.09  48.327499  46.396736  86264000      1   Neutral   \n",
       "\n",
       "      sentiment_numeric  P_news_pos  P_news_neg  P_op_pos  P_op_neg  \n",
       "9679                  0         0.0         0.0  0.814815   0.12963  \n",
       "9680                  0         0.0         0.0  0.814815   0.12963  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_to_query = pd.to_datetime('2018-05-06')\n",
    "category_to_query = 'news'\n",
    "data_sorted.loc[(data_sorted['Date'] == date_to_query) & (data_sorted['category'] == category_to_query)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data['P_news_neg'].fillna(0, inplace=True)\n",
    "daily_data['P_news_pos'].fillna(0, inplace=True)\n",
    "daily_data['P_op_neg'].fillna(0, inplace=True)\n",
    "daily_data['P_op_pos'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不直接删除，而是存到新的df中。保留'date'列\n",
    "columns_to_keep = [col for col in daily_data.columns if col not in ['ticker', 'Adj Close', 'sentiment', 'sentiment_numeric', 'title', 'category', 'content', 'label']]\n",
    "daily_data_selected = daily_data[columns_to_keep]\n",
    "# 将'Date'列设置为daily_data_selected的索引，并将其排到第一位\n",
    "daily_data_selected = daily_data_selected.reset_index()\n",
    "daily_data_selected.set_index('Date', inplace=True)\n",
    "daily_data_selected = daily_data_selected.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>P_news_pos</th>\n",
       "      <th>P_news_neg</th>\n",
       "      <th>P_op_pos</th>\n",
       "      <th>P_op_neg</th>\n",
       "      <th>Next_Open</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-07-23</th>\n",
       "      <td>21.228571</td>\n",
       "      <td>21.639286</td>\n",
       "      <td>20.989643</td>\n",
       "      <td>21.565357</td>\n",
       "      <td>487975600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>21.692142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-24</th>\n",
       "      <td>21.692142</td>\n",
       "      <td>21.774286</td>\n",
       "      <td>21.375357</td>\n",
       "      <td>21.461430</td>\n",
       "      <td>565132400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.536072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-27</th>\n",
       "      <td>20.536072</td>\n",
       "      <td>20.922501</td>\n",
       "      <td>20.413929</td>\n",
       "      <td>20.898571</td>\n",
       "      <td>403936400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.104286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-30</th>\n",
       "      <td>21.104286</td>\n",
       "      <td>21.408571</td>\n",
       "      <td>20.993570</td>\n",
       "      <td>21.251072</td>\n",
       "      <td>379142400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.543928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-07-31</th>\n",
       "      <td>21.543928</td>\n",
       "      <td>21.846430</td>\n",
       "      <td>21.525715</td>\n",
       "      <td>21.812857</td>\n",
       "      <td>462327600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.102858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close     Volume  P_news_pos  \\\n",
       "Date                                                                            \n",
       "2012-07-23  21.228571  21.639286  20.989643  21.565357  487975600         0.0   \n",
       "2012-07-24  21.692142  21.774286  21.375357  21.461430  565132400         0.0   \n",
       "2012-07-27  20.536072  20.922501  20.413929  20.898571  403936400         0.0   \n",
       "2012-07-30  21.104286  21.408571  20.993570  21.251072  379142400         0.0   \n",
       "2012-07-31  21.543928  21.846430  21.525715  21.812857  462327600         0.0   \n",
       "\n",
       "            P_news_neg  P_op_pos  P_op_neg  Next_Open  \n",
       "Date                                                   \n",
       "2012-07-23         0.0  0.333333  0.333333  21.692142  \n",
       "2012-07-24         0.0  0.000000  0.000000  20.536072  \n",
       "2012-07-27         0.0  0.000000  1.000000  21.104286  \n",
       "2012-07-30         0.0  0.000000  1.000000  21.543928  \n",
       "2012-07-31         0.0  0.500000  0.000000  23.102858  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_data_selected.to_csv('./data/dataset_for_model.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Stock price prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "daily_data_selected = pd.read_csv('./data/dataset_for_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>P_news_pos</th>\n",
       "      <th>P_news_neg</th>\n",
       "      <th>P_op_pos</th>\n",
       "      <th>P_op_neg</th>\n",
       "      <th>Next_Open</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21.228571</td>\n",
       "      <td>21.639286</td>\n",
       "      <td>20.989643</td>\n",
       "      <td>21.565357</td>\n",
       "      <td>487975600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>21.692142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.692142</td>\n",
       "      <td>21.774286</td>\n",
       "      <td>21.375357</td>\n",
       "      <td>21.461430</td>\n",
       "      <td>565132400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.536072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20.536072</td>\n",
       "      <td>20.922501</td>\n",
       "      <td>20.413929</td>\n",
       "      <td>20.898571</td>\n",
       "      <td>403936400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.104286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21.104286</td>\n",
       "      <td>21.408571</td>\n",
       "      <td>20.993570</td>\n",
       "      <td>21.251072</td>\n",
       "      <td>379142400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.543928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.543928</td>\n",
       "      <td>21.846430</td>\n",
       "      <td>21.525715</td>\n",
       "      <td>21.812857</td>\n",
       "      <td>462327600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.102858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>79.067497</td>\n",
       "      <td>79.684998</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>79.682503</td>\n",
       "      <td>137816400</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79.297501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>79.297501</td>\n",
       "      <td>79.754997</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.142502</td>\n",
       "      <td>110843200</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>79.644997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>79.644997</td>\n",
       "      <td>79.997498</td>\n",
       "      <td>79.327499</td>\n",
       "      <td>79.425003</td>\n",
       "      <td>101832400</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>79.480003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>79.480003</td>\n",
       "      <td>79.889999</td>\n",
       "      <td>78.912498</td>\n",
       "      <td>79.807503</td>\n",
       "      <td>104472000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>80.062500</td>\n",
       "      <td>80.832497</td>\n",
       "      <td>79.379997</td>\n",
       "      <td>79.577499</td>\n",
       "      <td>146537600</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.514999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1653 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open       High        Low      Close     Volume  P_news_pos  \\\n",
       "0     21.228571  21.639286  20.989643  21.565357  487975600    0.000000   \n",
       "1     21.692142  21.774286  21.375357  21.461430  565132400    0.000000   \n",
       "2     20.536072  20.922501  20.413929  20.898571  403936400    0.000000   \n",
       "3     21.104286  21.408571  20.993570  21.251072  379142400    0.000000   \n",
       "4     21.543928  21.846430  21.525715  21.812857  462327600    0.000000   \n",
       "...         ...        ...        ...        ...        ...         ...   \n",
       "1648  79.067497  79.684998  78.750000  79.682503  137816400    0.500000   \n",
       "1649  79.297501  79.754997  79.000000  79.142502  110843200    0.200000   \n",
       "1650  79.644997  79.997498  79.327499  79.425003  101832400    0.333333   \n",
       "1651  79.480003  79.889999  78.912498  79.807503  104472000    0.461538   \n",
       "1652  80.062500  80.832497  79.379997  79.577499  146537600    0.416667   \n",
       "\n",
       "      P_news_neg  P_op_pos  P_op_neg  Next_Open  \n",
       "0       0.000000  0.333333  0.333333  21.692142  \n",
       "1       0.000000  0.000000  0.000000  20.536072  \n",
       "2       0.000000  0.000000  1.000000  21.104286  \n",
       "3       0.000000  0.000000  1.000000  21.543928  \n",
       "4       0.000000  0.500000  0.000000  23.102858  \n",
       "...          ...       ...       ...        ...  \n",
       "1648    0.250000  0.700000  0.000000  79.297501  \n",
       "1649    0.200000  0.523810  0.238095  79.644997  \n",
       "1650    0.200000  0.666667  0.066667  79.480003  \n",
       "1651    0.076923  0.909091  0.000000  80.062500  \n",
       "1652    0.166667  0.750000  0.000000  77.514999  \n",
       "\n",
       "[1653 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_data_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1648</th>\n",
       "      <td>79.067497</td>\n",
       "      <td>79.684998</td>\n",
       "      <td>78.750000</td>\n",
       "      <td>79.682503</td>\n",
       "      <td>137816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1649</th>\n",
       "      <td>79.297501</td>\n",
       "      <td>79.754997</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>79.142502</td>\n",
       "      <td>110843200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650</th>\n",
       "      <td>79.644997</td>\n",
       "      <td>79.997498</td>\n",
       "      <td>79.327499</td>\n",
       "      <td>79.425003</td>\n",
       "      <td>101832400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1651</th>\n",
       "      <td>79.480003</td>\n",
       "      <td>79.889999</td>\n",
       "      <td>78.912498</td>\n",
       "      <td>79.807503</td>\n",
       "      <td>104472000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>80.062500</td>\n",
       "      <td>80.832497</td>\n",
       "      <td>79.379997</td>\n",
       "      <td>79.577499</td>\n",
       "      <td>146537600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open       High        Low      Close     Volume\n",
       "1648  79.067497  79.684998  78.750000  79.682503  137816400\n",
       "1649  79.297501  79.754997  79.000000  79.142502  110843200\n",
       "1650  79.644997  79.997498  79.327499  79.425003  101832400\n",
       "1651  79.480003  79.889999  78.912498  79.807503  104472000\n",
       "1652  80.062500  80.832497  79.379997  79.577499  146537600"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 选择特征和目标\n",
    "# features = daily_data_selected.drop('Next_Open', axis=1)\n",
    "features = daily_data_selected.drop(['Next_Open', 'P_news_pos', 'P_news_neg', 'P_op_pos', 'P_op_neg'], axis=1)\n",
    "# Open作为预测目标\n",
    "target = daily_data_selected['Open']\n",
    "features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Apply the MinMaxScaler to the features and target\n",
    "scaler_features = MinMaxScaler()\n",
    "scaler_target = MinMaxScaler()\n",
    "\n",
    "# fit_transform根据数据计算缩放参数\n",
    "scaled_features = scaler_features.fit_transform(features)\n",
    "scaled_target = scaler_target.fit_transform(target.values.reshape(-1, 1))\n",
    "\n",
    "# 保存缩放参数\n",
    "import joblib\n",
    "joblib.dump(scaler_features, './model/scaler_features.pkl')\n",
    "joblib.dump(scaler_target, './model/scaler_target.pkl')\n",
    "\n",
    "# Create new DataFrames with the scaled features and target\n",
    "scaled_features_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "scaled_target_df = pd.DataFrame(scaled_target, columns=['Open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(features, targets, seq_length):\n",
    "    \"\"\"\n",
    "    Create sequences of specified length from time series data.\n",
    "\n",
    "    Args:\n",
    "    features (np.array): The feature data.\n",
    "    targets (np.array): The target data.\n",
    "    seq_length (int): The length of the sequence.\n",
    "\n",
    "    Returns:\n",
    "    np.array: Sequences of features.\n",
    "    np.array: Corresponding targets for each sequence.\n",
    "    \"\"\"\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        x = features[i:(i + seq_length)]\n",
    "        y = targets[i + seq_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Example sequence length\n",
    "seq_length = 20\n",
    "\n",
    "# Create sequences\n",
    "features_seq, target_seq = create_sequences(scaled_features, scaled_target, seq_length)\n",
    "\n",
    "# Convert sequences to Tensor\n",
    "features_tensor = torch.tensor(features_seq, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(target_seq, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分训练集、验证集、测试集\n",
    "train_features, test_features, train_target, test_target = train_test_split(\n",
    "    scaled_features, scaled_target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "val_features, test_features, val_target, test_target = train_test_split(\n",
    "    test_features, test_target, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# 创建TensorDataset\n",
    "train_dataset = TensorDataset(torch.tensor(train_features, dtype=torch.float32),\n",
    "                              torch.tensor(train_target, dtype=torch.float32))\n",
    "\n",
    "val_dataset = TensorDataset(torch.tensor(val_features, dtype=torch.float32),\n",
    "                            torch.tensor(val_target, dtype=torch.float32))\n",
    "\n",
    "test_dataset = TensorDataset(torch.tensor(test_features, dtype=torch.float32),\n",
    "                             torch.tensor(test_target, dtype=torch.float32))\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用普通的LSTM模型，不使用注意力机制\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_size, num_layers, output_dim, dropout=0.2):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM层\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_size, num_layers, \n",
    "                            batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        \n",
    "        # 全连接层\n",
    "        self.fc = nn.Linear(hidden_size, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # 取最后一个时间步的输出\n",
    "        output = self.fc(lstm_out[:, -1, :])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "input_dim = scaled_features_df.shape[1]  # 特征数量\n",
    "hidden_size = 100  # 隐藏状态中的特征数量，可以调整\n",
    "num_layers = 4    # 堆叠的LSTM层的数量\n",
    "output_dim = 1    # 输出维度的数量（预测一个值）\n",
    "\n",
    "# 实例化模型时添加Dropout\n",
    "model = SimpleLSTM(input_dim, hidden_size, num_layers, output_dim, dropout=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 60  # Can be adjusted\n",
    "\n",
    "# 在训练循环中添加对验证集的检查\n",
    "best_val_loss = float('inf')\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # 在每个epoch结束后评估验证集\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in val_loader:\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss += criterion(val_outputs, val_labels).item()\n",
    "    val_loss /= len(val_loader)\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "    print(f'Epoch {epoch+1}, Training Loss: {loss.item()}, Validation Loss: {val_loss}')\n",
    "    \n",
    "    # 检查是否有更低的验证损失\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), './model/best_model.pth')  # 保存最好的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('./model/best_model.pth'))\n",
    "\n",
    "# 从测试集中提取特征和目标\n",
    "# 改为val_dataset\n",
    "test_features = val_dataset[:][0]\n",
    "test_target = val_dataset[:][1]\n",
    "\n",
    "# 创建滑动窗口\n",
    "test_features_seq, test_target_seq = create_sequences(test_features.numpy(), test_target.numpy(), seq_length)\n",
    "\n",
    "# 将序列转换为Tensor\n",
    "test_features_tensor = torch.tensor(test_features_seq, dtype=torch.float32)\n",
    "test_target_tensor = torch.tensor(test_target_seq, dtype=torch.float32)\n",
    "\n",
    "# 使用模型进行预测\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(test_features_tensor).numpy()\n",
    "\n",
    "# 反缩放预测值\n",
    "test_predictions = scaler_target.inverse_transform(test_predictions).flatten()\n",
    "\n",
    "# 反缩放真实目标值\n",
    "test_target = scaler_target.inverse_transform(test_target_tensor.numpy()).flatten()\n",
    "\n",
    "# 绘制实际股价和预测股价的对比图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_target[seq_length:], label='Actual Prices', color='blue')\n",
    "plt.plot(test_predictions, label='Predicted Prices', color='red')\n",
    "plt.title('Predicted vs Actual Prices')\n",
    "plt.xlabel('Time Step')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(test_target, test_predictions))\n",
    "print('Test RMSE: ', rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "# 加载最佳模型\n",
    "model.load_state_dict(torch.load('./model/best_model.pth'))\n",
    "\n",
    "# 提取最后n个数据点\n",
    "test_length = 100\n",
    "last_n = daily_data_selected[-test_length:]\n",
    "\n",
    "# 保存最后n个日期，这将用于绘图\n",
    "last_n_dates = last_n.index\n",
    "\n",
    "# 删除日期和目标列以准备缩放\n",
    "last_n_features = last_n.drop(['Next_Open'], axis=1)\n",
    "last_n_target = last_n['Open']\n",
    "\n",
    "# 仅在scaler_features/scaler_target在当前内存中不存在时，才从文件中加载保存的缩放器状态\n",
    "if 'scaler_features' not in locals():\n",
    "    scaler_features = joblib.load('./model/scaler_features.pkl')\n",
    "if 'scaler_target' not in locals():\n",
    "    scaler_target = joblib.load('./model/scaler_target.pkl')\n",
    "\n",
    "# 缩放特征\n",
    "# transform应用此前的缩放参数，而不要重新计算\n",
    "# last_n_scaled_features = scaler_features.transform(last_n_features)\n",
    "features = daily_data_selected.drop(['Next_Open', 'P_news_pos', 'P_news_neg', 'P_op_pos', 'P_op_neg'], axis=1)\n",
    "\n",
    "\n",
    "# 定义窗口长度\n",
    "window_length = seq_length\n",
    "\n",
    "# 创建包含所有窗口的数据集\n",
    "batched_windows = []\n",
    "for i in range(test_length - window_length + 1):\n",
    "    window = last_n_scaled_features[i:i + window_length]\n",
    "    batched_windows.append(window)\n",
    "batched_windows = np.array(batched_windows)\n",
    "\n",
    "# 将数据转换为Tensor\n",
    "batched_windows_tensor = torch.tensor(batched_windows, dtype=torch.float32)\n",
    "\n",
    "# 使用模型进行预测\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    batch_predictions = model(batched_windows_tensor).numpy()\n",
    "\n",
    "# 反缩放预测值\n",
    "batch_predictions = scaler_target.inverse_transform(batch_predictions).flatten()\n",
    "\n",
    "# 绘制实际股价和批量预测股价的对比图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(last_n_dates[window_length - 1:], last_n_target[window_length - 1:], label='Actual Prices', color='blue')\n",
    "plt.plot(last_n_dates[window_length - 1:], batch_predictions, label='Batch Predicted Prices', color='red')\n",
    "plt.title('Batch Predicted Prices')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 滑动窗口预测\n",
    "true_predictions = []\n",
    "for i in range(test_length):\n",
    "    if i < window_length:\n",
    "        continue\n",
    "    window = last_n_scaled_features[i-window_length:i]\n",
    "    window_tensor = torch.tensor(window, dtype=torch.float32).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(window_tensor).numpy()\n",
    "    true_prediction = scaler_target.inverse_transform(prediction).flatten()[0]\n",
    "    true_predictions.append(true_prediction)\n",
    "    \n",
    "# 绘制第一张图 \n",
    "plt.figure(figsize=(10, 6))\n",
    "# TODO\n",
    "plt.plot(last_n_dates, last_n_target, label='Actual Prices', color='blue')\n",
    "plt.plot(last_n_dates[window_length:], true_predictions, label='Predicted Prices', color='red')\n",
    "plt.title('Sliding Window Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 递归预测\n",
    "recursive_predictions = last_n_scaled_features[-window_length:].tolist()  # 初始窗口\n",
    "for i in range(test_length // 2):\n",
    "    window_tensor = torch.tensor(recursive_predictions[-window_length:], dtype=torch.float32).unsqueeze(0)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(window_tensor).numpy()\n",
    "    recursive_predictions.append(prediction[0])\n",
    "\n",
    "# 反缩放递归预测\n",
    "recursive_predictions = scaler_target.inverse_transform(np.array(recursive_predictions).reshape(-1, 1)).flatten()\n",
    "\n",
    "# 绘制第二张图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(last_n_dates, last_n_target, label='Actual Prices', color='blue')\n",
    "plt.plot(last_n_dates, recursive_predictions[:test_length], label='Recursive Predicted Prices', color='red')\n",
    "plt.title('Recursive Prediction')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设您的模型已经被训练并准备好进行预测\n",
    "# 我们将使用最后一个时间窗口的数据来预测接下来的n个时间点\n",
    "# 为此，我们需要从数据集的末尾向前回溯一个窗口长度的数据点\n",
    "\n",
    "# 定义窗口长度\n",
    "window_length = 15  # 与您模型训练时使用的序列长度一致\n",
    "\n",
    "# 预测未来n个时间点的函数\n",
    "def predict_next_n(model, last_window_data, num_predictions=n):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    current_window = last_window_data\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_predictions):\n",
    "            # 使用当前窗口数据进行预测\n",
    "            current_window_tensor = torch.tensor(current_window, dtype=torch.float32).unsqueeze(0)  # 增加batch维度\n",
    "            prediction = model(current_window_tensor)\n",
    "            prediction = prediction.numpy().flatten()[0]  # 将预测结果转换为numpy并提取数值\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "            # 更新窗口数据：移除最早的点，加入最新预测\n",
    "            current_window = np.roll(current_window, -1)\n",
    "            current_window[-1] = prediction  # 这里假设您的目标是最后一个特征\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# 获取最后一个时间窗口的数据\n",
    "last_window_data = last_n_scaled_features[-window_length:]\n",
    "\n",
    "# 预测下一个n个时间点\n",
    "next_n_predictions_scaled = predict_next_n(model, last_window_data)\n",
    "\n",
    "# 反缩放预测值\n",
    "next_n_predictions = scaler_target.inverse_transform(np.array(next_n_predictions_scaled).reshape(-1, 1))\n",
    "\n",
    "# 现在您有了未来n个时间点的预测，可以与实际数据进行比较\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
